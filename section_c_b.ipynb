{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section C - (B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Function to load and process data files\n",
    "def load_data(file_pattern, label):\n",
    "    \"\"\"\n",
    "    Load and process data files, assigning a label for each event.\n",
    "    \n",
    "    Args:\n",
    "        file_pattern: Pattern for glob to find files\n",
    "        label: Label for this category (0=bb, 1=cc, 2=ss)\n",
    "    \n",
    "    Returns:\n",
    "        List of event dictionaries with features and labels\n",
    "    \"\"\"\n",
    "    files = glob.glob(file_pattern)\n",
    "    events = []\n",
    "    \n",
    "    for file_path in files:\n",
    "        print(f\"Loading {file_path}...\")\n",
    "        # Read root file using uproot\n",
    "        try:\n",
    "            import uproot\n",
    "            with uproot.open(file_path) as file:\n",
    "                tree = file[\"events\"]\n",
    "                # Get all branches\n",
    "                branches = tree.arrays()\n",
    "                \n",
    "                # Process each event\n",
    "                num_events = len(branches[\"n_jet\"])\n",
    "                for i in range(num_events):\n",
    "                    event = {}\n",
    "                    event['n_jet'] = branches[\"n_jet\"][i]\n",
    "                    event['n_trk'] = branches[\"n_trk\"][i]\n",
    "                    \n",
    "                    # Get jet features - for simplicity, let's use the first two jets\n",
    "                    max_jets = 2\n",
    "                    jets = []\n",
    "                    for j in range(min(event['n_jet'], max_jets)):\n",
    "                        jet = {}\n",
    "                        jet['pt'] = branches[\"jet_pt\"][i][j]\n",
    "                        jet['eta'] = branches[\"jet_eta\"][i][j]\n",
    "                        jet['phi'] = branches[\"jet_phi\"][i][j]\n",
    "                        jet['e'] = branches[\"jet_e\"][i][j]\n",
    "                        # Add other jet features if available\n",
    "                        if \"jet_btag\" in branches:\n",
    "                            jet['btag'] = branches[\"jet_btag\"][i][j]\n",
    "                        jets.append(jet)\n",
    "                    \n",
    "                    # Get track features - limit to a manageable number per event\n",
    "                    max_tracks = 20\n",
    "                    tracks = []\n",
    "                    for j in range(min(event['n_trk'], max_tracks)):\n",
    "                        track = {}\n",
    "                        track['pt'] = branches[\"trk_pt\"][i][j]\n",
    "                        track['eta'] = branches[\"trk_eta\"][i][j]\n",
    "                        track['phi'] = branches[\"trk_phi\"][i][j]\n",
    "                        # Add other track features if available\n",
    "                        if \"trk_d0\" in branches:\n",
    "                            track['d0'] = branches[\"trk_d0\"][i][j]\n",
    "                        if \"trk_z0\" in branches:\n",
    "                            track['z0'] = branches[\"trk_z0\"][i][j]\n",
    "                        tracks.append(track)\n",
    "                    \n",
    "                    event['jets'] = jets\n",
    "                    event['tracks'] = tracks\n",
    "                    event['label'] = label\n",
    "                    events.append(event)\n",
    "                \n",
    "        except Exception as e:\n",
    "            # If uproot isn't available or fails, try a fallback approach\n",
    "            # This is a placeholder - in reality, you would need to implement an alternative loading method\n",
    "            print(f\"Error loading file with uproot: {e}\")\n",
    "            print(\"Please ensure uproot is installed or provide an alternative loading method.\")\n",
    "            \n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Placeholder for loading paths - replace with actual paths\n",
    "bb_files = \"path/to/bb_files/*.root\"  # Replace with actual path\n",
    "cc_files = \"path/to/cc_files/*.root\"  # Replace with actual path\n",
    "ss_files = \"path/to/ss_files/*.root\"  # Replace with actual path\n",
    "\n",
    "# For demonstration, I'll create placeholder data\n",
    "# In your actual solution, load real data using the function above\n",
    "print(\"Creating placeholder data for demonstration...\")\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Function to create sample synthetic event data\n",
    "def create_sample_data(n_events, flavor='b'):\n",
    "    \"\"\"Create synthetic data for demonstration\"\"\"\n",
    "    events = []\n",
    "    \n",
    "    # Set parameters based on quark flavor to simulate different distributions\n",
    "    if flavor == 'b':\n",
    "        label = 0\n",
    "        pt_mean, pt_std = 40, 15\n",
    "        track_mult = 10\n",
    "        btag_mean = 0.8\n",
    "    elif flavor == 'c':\n",
    "        label = 1\n",
    "        pt_mean, pt_std = 35, 10\n",
    "        track_mult = 8\n",
    "        btag_mean = 0.5\n",
    "    else:  # 's'\n",
    "        label = 2\n",
    "        pt_mean, pt_std = 30, 8\n",
    "        track_mult = 6\n",
    "        btag_mean = 0.2\n",
    "    \n",
    "    for i in range(n_events):\n",
    "        event = {}\n",
    "        n_jets = np.random.randint(2, 5)\n",
    "        n_tracks = np.random.poisson(track_mult)\n",
    "        \n",
    "        event['n_jet'] = n_jets\n",
    "        event['n_trk'] = n_tracks\n",
    "        \n",
    "        # Generate jets\n",
    "        jets = []\n",
    "        for j in range(n_jets):\n",
    "            jet = {}\n",
    "            jet['pt'] = max(5, np.random.normal(pt_mean, pt_std))\n",
    "            jet['eta'] = np.random.normal(0, 1)\n",
    "            jet['phi'] = np.random.uniform(-np.pi, np.pi)\n",
    "            jet['e'] = jet['pt'] * np.cosh(jet['eta']) * (1 + np.random.normal(0, 0.1))\n",
    "            jet['btag'] = np.clip(np.random.normal(btag_mean, 0.2), 0, 1)\n",
    "            jets.append(jet)\n",
    "        \n",
    "        # Generate tracks\n",
    "        tracks = []\n",
    "        for j in range(n_tracks):\n",
    "            track = {}\n",
    "            track['pt'] = max(0.5, np.random.exponential(5))\n",
    "            track['eta'] = np.random.normal(0, 1.5)\n",
    "            track['phi'] = np.random.uniform(-np.pi, np.pi)\n",
    "            \n",
    "            # Impact parameters are more interesting for b and c jets\n",
    "            if flavor == 'b':\n",
    "                track['d0'] = np.random.normal(0, 0.02)\n",
    "                track['z0'] = np.random.normal(0, 0.05)\n",
    "            elif flavor == 'c':\n",
    "                track['d0'] = np.random.normal(0, 0.01)\n",
    "                track['z0'] = np.random.normal(0, 0.03)\n",
    "            else:\n",
    "                track['d0'] = np.random.normal(0, 0.005)\n",
    "                track['z0'] = np.random.normal(0, 0.01)\n",
    "                \n",
    "            tracks.append(track)\n",
    "        \n",
    "        event['jets'] = jets\n",
    "        event['tracks'] = tracks\n",
    "        event['label'] = label\n",
    "        events.append(event)\n",
    "    \n",
    "    return events\n",
    "\n",
    "# Create synthetic data for demonstration\n",
    "bb_events = create_sample_data(1000, 'b')\n",
    "cc_events = create_sample_data(1000, 'c')\n",
    "ss_events = create_sample_data(1000, 's')\n",
    "\n",
    "# Combine all events\n",
    "all_events = bb_events + cc_events + ss_events\n",
    "np.random.shuffle(all_events)\n",
    "\n",
    "print(f\"Created {len(all_events)} synthetic events\")\n",
    "print(f\"b-jets: {len(bb_events)}, c-jets: {len(cc_events)}, s-jets: {len(ss_events)}\")\n",
    "\n",
    "# Explore the data structure\n",
    "sample_event = all_events[0]\n",
    "print(\"\\nSample event structure:\")\n",
    "print(f\"Label: {sample_event['label']} ({['b', 'c', 's'][sample_event['label']]})\")\n",
    "print(f\"Number of jets: {sample_event['n_jet']}\")\n",
    "print(f\"Number of tracks: {sample_event['n_trk']}\")\n",
    "print(f\"First jet properties: {sample_event['jets'][0]}\")\n",
    "print(f\"First track properties: {sample_event['tracks'][0]}\")\n",
    "\n",
    "# Extract some features for visualization\n",
    "flavor_labels = [event['label'] for event in all_events]\n",
    "n_jets = [event['n_jet'] for event in all_events]\n",
    "n_tracks = [event['n_trk'] for event in all_events]\n",
    "btag_values = []\n",
    "leading_jet_pt = []\n",
    "\n",
    "for event in all_events:\n",
    "    if len(event['jets']) > 0 and 'btag' in event['jets'][0]:\n",
    "        btag_values.append(event['jets'][0]['btag'])\n",
    "        leading_jet_pt.append(event['jets'][0]['pt'])\n",
    "    else:\n",
    "        btag_values.append(float('nan'))\n",
    "        leading_jet_pt.append(float('nan'))\n",
    "\n",
    "# Create a dataframe for easier visualization\n",
    "df = pd.DataFrame({\n",
    "    'flavor': [['b', 'c', 's'][label] for label in flavor_labels],\n",
    "    'n_jets': n_jets,\n",
    "    'n_tracks': n_tracks,\n",
    "    'btag': btag_values,\n",
    "    'leading_jet_pt': leading_jet_pt\n",
    "})\n",
    "\n",
    "# Visualize some distributions\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.histplot(data=df, x='n_jets', hue='flavor', multiple='stack', discrete=True)\n",
    "plt.title('Number of Jets by Flavor')\n",
    "plt.xlabel('Number of Jets')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.histplot(data=df, x='n_tracks', hue='flavor', multiple='stack', bins=20)\n",
    "plt.title('Number of Tracks by Flavor')\n",
    "plt.xlabel('Number of Tracks')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.histplot(data=df, x='btag', hue='flavor', multiple='stack', bins=20)\n",
    "plt.title('b-tag Score by Flavor')\n",
    "plt.xlabel('b-tag Score')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.histplot(data=df, x='leading_jet_pt', hue='flavor', multiple='stack', bins=20)\n",
    "plt.title('Leading Jet pT by Flavor')\n",
    "plt.xlabel('Leading Jet pT (GeV)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('data_exploration.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"\\nData exploration completed and visualizations saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Feature extraction for the neural network\n",
    "def extract_features(events, max_jets=4, max_tracks=20):\n",
    "    \"\"\"\n",
    "    Extract features from events for input to neural networks.\n",
    "    \n",
    "    Returns:\n",
    "        X_jets: Array of jet features for each event\n",
    "        X_tracks: Array of track features for each event\n",
    "        y: Labels\n",
    "    \"\"\"\n",
    "    n_events = len(events)\n",
    "    \n",
    "    # Define feature dimensions\n",
    "    n_jet_features = 5  # pt, eta, phi, e, btag\n",
    "    n_track_features = 5  # pt, eta, phi, d0, z0\n",
    "    \n",
    "    # Initialize arrays\n",
    "    X_jets = np.zeros((n_events, max_jets, n_jet_features))\n",
    "    X_tracks = np.zeros((n_events, max_tracks, n_track_features))\n",
    "    y = np.zeros(n_events, dtype=int)\n",
    "    \n",
    "    # Fill arrays with data\n",
    "    for i, event in enumerate(events):\n",
    "        # Fill label\n",
    "        y[i] = event['label']\n",
    "        \n",
    "        # Fill jet features\n",
    "        for j, jet in enumerate(event['jets'][:max_jets]):\n",
    "            X_jets[i, j, 0] = jet['pt']\n",
    "            X_jets[i, j, 1] = jet['eta']\n",
    "            X_jets[i, j, 2] = jet['phi']\n",
    "            X_jets[i, j, 3] = jet['e']\n",
    "            X_jets[i, j, 4] = jet.get('btag', 0)  # Default to 0 if btag not available\n",
    "        \n",
    "        # Fill track features\n",
    "        for j, track in enumerate(event['tracks'][:max_tracks]):\n",
    "            X_tracks[i, j, 0] = track['pt']\n",
    "            X_tracks[i, j, 1] = track['eta']\n",
    "            X_tracks[i, j, 2] = track['phi']\n",
    "            X_tracks[i, j, 3] = track.get('d0', 0)  # Default to 0 if d0 not available\n",
    "            X_tracks[i, j, 4] = track.get('z0', 0)  # Default to 0 if z0 not available\n",
    "    \n",
    "    return X_jets, X_tracks, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Extract features\n",
    "X_jets, X_tracks, y = extract_features(all_events)\n",
    "\n",
    "# Split data into training, validation, and test sets\n",
    "X_jets_train, X_jets_test, X_tracks_train, X_tracks_test, y_train, y_test = train_test_split(\n",
    "    X_jets, X_tracks, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_jets_train, X_jets_val, X_tracks_train, X_tracks_val, y_train, y_val = train_test_split(\n",
    "    X_jets_train, X_tracks_train, y_train, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Data split complete:\")\n",
    "print(f\"Training: {len(y_train)} samples\")\n",
    "print(f\"Validation: {len(y_val)} samples\")\n",
    "print(f\"Test: {len(y_test)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Normalize the data (this is important for neural networks)\n",
    "# For simplicity, we'll use a simple approach here\n",
    "def normalize_features(X_train, X_val, X_test):\n",
    "    # Reshape to 2D for scaling\n",
    "    orig_shape = X_train.shape\n",
    "    X_train_flat = X_train.reshape(-1, X_train.shape[-1])\n",
    "    X_val_flat = X_val.reshape(-1, X_val.shape[-1])\n",
    "    X_test_flat = X_test.reshape(-1, X_test.shape[-1])\n",
    "    \n",
    "    # Fit scaler on training data\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train_flat)\n",
    "    \n",
    "    # Transform all datasets\n",
    "    X_train_scaled = scaler.transform(X_train_flat).reshape(orig_shape)\n",
    "    X_val_scaled = scaler.transform(X_val_flat).reshape(X_val.shape)\n",
    "    X_test_scaled = scaler.transform(X_test_flat).reshape(X_test.shape)\n",
    "    \n",
    "    return X_train_scaled, X_val_scaled, X_test_scaled\n",
    "\n",
    "# Normalize jet and track features separately\n",
    "X_jets_train_norm, X_jets_val_norm, X_jets_test_norm = normalize_features(\n",
    "    X_jets_train, X_jets_val, X_jets_test\n",
    ")\n",
    "X_tracks_train_norm, X_tracks_val_norm, X_tracks_test_norm = normalize_features(\n",
    "    X_tracks_train, X_tracks_val, X_tracks_test\n",
    ")\n",
    "\n",
    "print(\"Data normalization complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Build a model using the Keras functional API\n",
    "# We'll use a combination of RNN and DeepSets approaches\n",
    "def build_model(max_jets, max_tracks, n_jet_features, n_track_features, n_classes=3):\n",
    "    \"\"\"\n",
    "    Build a neural network model for event classification.\n",
    "    Uses both jet and track information.\n",
    "    \"\"\"\n",
    "    # Jet inputs and processing\n",
    "    jet_input = keras.Input(shape=(max_jets, n_jet_features), name='jet_input')\n",
    "    \n",
    "    # Process each jet with a shared dense network (DeepSets approach)\n",
    "    jet_dense = layers.Dense(64, activation='relu')(jet_input)\n",
    "    jet_dense = layers.Dense(32, activation='relu')(jet_dense)\n",
    "    \n",
    "    # Apply RNN to sequence of jets\n",
    "    jet_lstm = layers.Bidirectional(layers.LSTM(32))(jet_dense)\n",
    "    \n",
    "    # Track inputs and processing\n",
    "    track_input = keras.Input(shape=(max_tracks, n_track_features), name='track_input')\n",
    "    \n",
    "    # Process each track with a shared dense network\n",
    "    track_dense = layers.Dense(64, activation='relu')(track_input)\n",
    "    track_dense = layers.Dense(32, activation='relu')(track_dense)\n",
    "    \n",
    "    # Apply RNN to sequence of tracks\n",
    "    track_lstm = layers.Bidirectional(layers.LSTM(32))(track_dense)\n",
    "    \n",
    "    # Combine jet and track features\n",
    "    combined = layers.Concatenate()([jet_lstm, track_lstm])\n",
    "    \n",
    "    # Final classification layers\n",
    "    x = layers.Dense(64, activation='relu')(combined)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Dense(32, activation='relu')(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    \n",
    "    # Output layer with softmax activation for multi-class classification\n",
    "    output = layers.Dense(n_classes, activation='softmax', name='output')(x)\n",
    "    \n",
    "    # Create and compile model\n",
    "    model = keras.Model(inputs=[jet_input, track_input], outputs=output)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Build the model\n",
    "n_jet_features = X_jets_train.shape[2]\n",
    "n_track_features = X_tracks_train.shape[2]\n",
    "max_jets = X_jets_train.shape[1]\n",
    "max_tracks = X_tracks_train.shape[1]\n",
    "\n",
    "model = build_model(\n",
    "    max_jets=max_jets, \n",
    "    max_tracks=max_tracks, \n",
    "    n_jet_features=n_jet_features, \n",
    "    n_track_features=n_track_features\n",
    ")\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    [X_jets_train_norm, X_tracks_train_norm], \n",
    "    y_train,\n",
    "    validation_data=([X_jets_val_norm, X_tracks_val_norm], y_val),\n",
    "    epochs=30,\n",
    "    batch_size=64,\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            patience=5, \n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            factor=0.5, \n",
    "            patience=3\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate([X_jets_test_norm, X_tracks_test_norm], y_test)\n",
    "print(f\"\\nTest accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Get predictions\n",
    "y_pred_prob = model.predict([X_jets_test_norm, X_tracks_test_norm])\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Generate classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['b-jet', 'c-jet', 's-jet']))\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['b-jet', 'c-jet', 's-jet'],\n",
    "            yticklabels=['b-jet', 'c-jet', 's-jet'])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.close()\n",
    "\n",
    "# Plot ROC curves\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# One-vs-All ROC curves\n",
    "for i, flavor in enumerate(['b-jet', 'c-jet', 's-jet']):\n",
    "    # Convert to one-vs-all problem\n",
    "    y_test_binary = (y_test == i).astype(int)\n",
    "    \n",
    "    # Get ROC curve\n",
    "    fpr, tpr, _ = roc_curve(y_test_binary, y_pred_prob[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.plot(fpr, tpr, lw=2, label=f'{flavor} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curves')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.savefig('roc_curves.png')\n",
    "plt.close()\n",
    "\n",
    "# Visualize classifier outputs\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Create 3 subplots, one for each flavor\n",
    "for i, flavor in enumerate(['b-jet', 'c-jet', 's-jet']):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    \n",
    "    # Get indices of true examples for this flavor\n",
    "    true_indices = np.where(y_test == i)[0]\n",
    "    \n",
    "    # Plot distribution of classifier outputs for this flavor\n",
    "    for j, pred_flavor in enumerate(['b-jet', 'c-jet', 's-jet']):\n",
    "        plt.hist(y_pred_prob[true_indices, j], bins=25, alpha=0.7, \n",
    "                 label=f'Prob({pred_flavor})', range=(0, 1))\n",
    "    \n",
    "    plt.title(f'True {flavor}')\n",
    "    plt.xlabel('Classifier Output')\n",
    "    plt.ylabel('Events')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('classifier_outputs.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
